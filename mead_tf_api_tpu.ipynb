{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mead-tf-api-tpu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOz9DH9Zt3Si5uTEuqTi4xe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dpressel/mead-tutorials/blob/master/mead_tf_api_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCEqxpB7pZ0B",
        "colab_type": "text"
      },
      "source": [
        "**Running classification on a TPU cluster**\n",
        "\n",
        "This example code uses the API from Baseline to read a dataset, load word-embedding features, and create a basic convolutional neural network (CNN) to train on a dataset.\n",
        "\n",
        "The TPU has 8 cores available, and the batch size is set to 16 time that amount (128).\n",
        "\n",
        "To make this work, we are using the `tf.distribute` API which makes this very simple!\n",
        "\n",
        "To start running we need tensorflow installed, and `mead-baseline`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6GAujzmMFeH",
        "colab_type": "code",
        "outputId": "ac5f7969-b730-46a7-e2ac-1089afe4773b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "!pip install wheel\n",
        "!pip install tensorflow\n",
        "!pip install mead-baseline[tf2]\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (0.34.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.28.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (46.1.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: mead-baseline[tf2] in /usr/local/lib/python3.6/dist-packages (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from mead-baseline[tf2]) (1.12.0)\n",
            "Requirement already satisfied: mead-layers in /usr/local/lib/python3.6/dist-packages (from mead-baseline[tf2]) (2.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mead-baseline[tf2]) (1.18.4)\n",
            "Requirement already satisfied: tensorflow-addons; extra == \"tf2\" in /usr/local/lib/python3.6/dist-packages (from mead-baseline[tf2]) (0.8.3)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons; extra == \"tf2\"->mead-baseline[tf2]) (2.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIKfebAYqEAP",
        "colab_type": "text"
      },
      "source": [
        "To access the embeddings and models for classification we need to import them.  That adds them to the internal MEAD registry of available classes. This allows us to refer to them by name.  The `default` name corresponds to pre-trained word embeddings for the embeddings portion, and a CNN for the classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1P8FMuqQOA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import baseline\n",
        "from baseline.tf.embeddings import *\n",
        "from baseline.tf.classify import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPQU4PxiqiFQ",
        "colab_type": "text"
      },
      "source": [
        "We need to set up our TPUs before any work is done, and this also cleans up any caches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF2zz4PBMgBG",
        "colab_type": "code",
        "outputId": "c47dcc6e-d327-4dac-ce87-4cf4572e8f0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.27.113.194:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.27.113.194:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2GUFEx1quWi",
        "colab_type": "text"
      },
      "source": [
        "Next, will grab down a dataset and some word-embeddings to get us going"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCoreK4fO54R",
        "colab_type": "code",
        "outputId": "8b302934-7c60-45e7-e8af-cc82944d43b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "\n",
        "!wget https://www.dropbox.com/s/7jyi4pi894bh2qh/sst2.tar.gz?dl=1\n",
        "!tar -xzf 'sst2.tar.gz?dl=1'\n",
        "!wget https://www.dropbox.com/s/699kgut7hdb5tg9/GoogleNews-vectors-negative300.bin.gz?dl=1\n",
        "!mv 'GoogleNews-vectors-negative300.bin.gz?dl=1' GoogleNews-vectors-negative300.bin.gz\n",
        "!gunzip GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-13 15:22:31--  https://www.dropbox.com/s/7jyi4pi894bh2qh/sst2.tar.gz?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.1, 2620:100:6018:1::a27d:301\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/7jyi4pi894bh2qh/sst2.tar.gz [following]\n",
            "--2020-05-13 15:22:31--  https://www.dropbox.com/s/dl/7jyi4pi894bh2qh/sst2.tar.gz\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucd9fc286a487bb28d7eb018d4ef.dl.dropboxusercontent.com/cd/0/get/A3pLLjAhWHh8F_ktEGMsKNFYk0oFoB5nXDEyu5m8QMVn6yC88F_L7XTwSsaydv_BK4NCrLk_ByxPggMcA7PHBICZ_U0_2Vfx4GR6_sLdl_io8g/file?dl=1# [following]\n",
            "--2020-05-13 15:22:32--  https://ucd9fc286a487bb28d7eb018d4ef.dl.dropboxusercontent.com/cd/0/get/A3pLLjAhWHh8F_ktEGMsKNFYk0oFoB5nXDEyu5m8QMVn6yC88F_L7XTwSsaydv_BK4NCrLk_ByxPggMcA7PHBICZ_U0_2Vfx4GR6_sLdl_io8g/file?dl=1\n",
            "Resolving ucd9fc286a487bb28d7eb018d4ef.dl.dropboxusercontent.com (ucd9fc286a487bb28d7eb018d4ef.dl.dropboxusercontent.com)... 162.125.3.6, 2620:100:6018:6::a27d:306\n",
            "Connecting to ucd9fc286a487bb28d7eb018d4ef.dl.dropboxusercontent.com (ucd9fc286a487bb28d7eb018d4ef.dl.dropboxusercontent.com)|162.125.3.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1759259 (1.7M) [application/binary]\n",
            "Saving to: ‘sst2.tar.gz?dl=1.4’\n",
            "\n",
            "sst2.tar.gz?dl=1.4  100%[===================>]   1.68M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-05-13 15:22:32 (14.6 MB/s) - ‘sst2.tar.gz?dl=1.4’ saved [1759259/1759259]\n",
            "\n",
            "--2020-05-13 15:22:33--  https://www.dropbox.com/s/699kgut7hdb5tg9/GoogleNews-vectors-negative300.bin.gz?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.1, 2620:100:6018:1::a27d:301\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/699kgut7hdb5tg9/GoogleNews-vectors-negative300.bin.gz [following]\n",
            "--2020-05-13 15:22:33--  https://www.dropbox.com/s/dl/699kgut7hdb5tg9/GoogleNews-vectors-negative300.bin.gz\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucb95fd1f88a33880e65df723e3f.dl.dropboxusercontent.com/cd/0/get/A3oO5nz8Eu3yu_NQer46Q5Vw8MJ5atjvIBjhiJs3WYaHFIRw42BfcQtywj4PGbxAr6mFiNvc8SNWZ67BwmSIrGYBoN8-WmugouwK131GZxDRSg/file?dl=1# [following]\n",
            "--2020-05-13 15:22:34--  https://ucb95fd1f88a33880e65df723e3f.dl.dropboxusercontent.com/cd/0/get/A3oO5nz8Eu3yu_NQer46Q5Vw8MJ5atjvIBjhiJs3WYaHFIRw42BfcQtywj4PGbxAr6mFiNvc8SNWZ67BwmSIrGYBoN8-WmugouwK131GZxDRSg/file?dl=1\n",
            "Resolving ucb95fd1f88a33880e65df723e3f.dl.dropboxusercontent.com (ucb95fd1f88a33880e65df723e3f.dl.dropboxusercontent.com)... 162.125.3.6, 2620:100:6018:6::a27d:306\n",
            "Connecting to ucb95fd1f88a33880e65df723e3f.dl.dropboxusercontent.com (ucb95fd1f88a33880e65df723e3f.dl.dropboxusercontent.com)|162.125.3.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1743563840 (1.6G) [application/binary]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz?dl=1’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.62G  44.5MB/s    in 38s     \n",
            "\n",
            "2020-05-13 15:23:12 (44.2 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz?dl=1’ saved [1743563840/1743563840]\n",
            "\n",
            "gzip: GoogleNews-vectors-negative300.bin already exists; do you wish to overwrite (y or n)? ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsCx4p80q860",
        "colab_type": "text"
      },
      "source": [
        "Here we are defining some constants associated with the training set, the maximum feature temporal length, and some fields that will help us set up our `tf.dataset`.  The `word_lengths` key is required by the Baseline classifier in order for it to recognize which dataset field contains the length of the tensor.  This isnt really important for our CNN, but it would be very important if we were using a BiLSTM, for example.  In general, the vectorizers will generate a length for each tensor that they read in based on the unpadded tensor length, and these are placed in the reader's batch dictionary for each batch.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kba4LEgHPWzu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48bd36c2-8014-4186-f8c5-f1d0c4bbbb90"
      },
      "source": [
        "BASE = 'sst2'\n",
        "TRAIN = os.path.join(BASE, 'stsa.binary.phrases.train')\n",
        "VALID = os.path.join(BASE, 'stsa.binary.dev')\n",
        "TEST = os.path.join(BASE, 'stsa.binary.test')\n",
        "PRETRAINED_EMBEDDINGS = 'GoogleNews-vectors-negative300.bin'\n",
        "MAX_FEAT_LEN = 100\n",
        "# Number of batches to prefetch if using tf.datasets\n",
        "NUM_PREFETCH = 2\n",
        "# The shuffle buffer\n",
        "SHUF_BUF_SZ = 5000\n",
        "LENGTHS_KEY = 'word_lengths'\n",
        "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
        "print(f'Using batch size {BATCH_SIZE}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using batch size 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3XFa2eDr46S",
        "colab_type": "text"
      },
      "source": [
        "Set up a dictionary of the features, with corresponding embeddings and a vectorizer that converts words to indices.\n",
        "\n",
        "Then make a reader that can uses these vectorizers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVaU9zXHMxlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "feature_desc = {\n",
        "    'word': {\n",
        "        'vectorizer': baseline.Token1DVectorizer(mxlen=MAX_FEAT_LEN, transform_fn=baseline.lowercase),\n",
        "        'embed': {'file': PRETRAINED_EMBEDDINGS, 'type': 'default', 'unif': 0.25}\n",
        "    }\n",
        "}\n",
        "vectorizers = {k: v['vectorizer'] for k, v in feature_desc.items()}\n",
        "reader = baseline.TSVSeqLabelReader(vectorizers,\n",
        "                              clean_fn=baseline.TSVSeqLabelReader.do_clean)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0cAywQdsGzl",
        "colab_type": "text"
      },
      "source": [
        "Set up our vocab, load our embeddings and create a word-to-index vocabulary for each embedding.  In this code example, there is only one feature, `word`, but MEAD supports many."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za4hBryRPtu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# This builds a set of counters\n",
        "vocabs, labels = reader.build_vocab([TRAIN, VALID, TEST])\n",
        "\n",
        "# This builds a set of embeddings objects, these are typically not DL-specific\n",
        "# but if they happen to be addons, they can be\n",
        "embeddings = dict()\n",
        "for k, v in feature_desc.items():\n",
        "    embed_config = v['embed']\n",
        "    embeddings_for_k = baseline.load_embeddings('word',\n",
        "                                                embed_file=embed_config['file'],\n",
        "                                                known_vocab=vocabs[k],\n",
        "                                                embed_type=embed_config.get('type', 'default'),\n",
        "                                                unif=embed_config.get('unif', 0.))\n",
        "\n",
        "    embeddings[k] = embeddings_for_k['embeddings']\n",
        "    # Reset the vocab to the embeddings one\n",
        "    vocabs[k] = embeddings_for_k['vocab']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r7Yez5UsTSY",
        "colab_type": "text"
      },
      "source": [
        "Set up our neural network using the `create_model` call.  This finds the appropriate classifier in our registry by the name given in `model_type`, and passes along the other parameters to the factory method that is registered to create this model, finally producing our CNN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQcRl-khQch5",
        "colab_type": "code",
        "outputId": "1da3a1af-1f6b-43ab-c089-af670c38f256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_params = {\n",
        "    'cmotsz': 300,\n",
        "    'filtsz': [3, 4, 5],\n",
        "    'model_type': 'default'\n",
        "}\n",
        "model = baseline.model.create_model(embeddings, labels, **model_params)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calling model <function register_model.<locals>.create at 0x7fe9b66dc0d0>\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0u9QHTQslbQ",
        "colab_type": "text"
      },
      "source": [
        "We couldve written a reader to load the dataset ourselves, but the `baseline.reader` module provides one for us.  However, its not exactly what we want -- we want the power of `tf.data.Datasets` and we need to then convert our reader's output to that.  To do this, we will use the utility function `to_tensors` which will convert the per-batch dictionaries that are produced by `reader.load` into tensor slices for use in the `tf.data.Dataset`\n",
        "\n",
        "The `tf.distribute` API provides a function to distribute our dataset over each replica.  The batches end up getting carved up and sent off to the appropriate replica under the hood.\n",
        "\n",
        "Our `create_dataset` code below encapsulates all of the logic we need to read from a file into a distributed dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIQyRzvcRDtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from baseline.tf.classify.training.utils import to_tensors\n",
        "\n",
        "def create_dataset(strategy, reader, filename, vocabs, batchsz, lengths_key, shuffle=False):\n",
        "    ts = reader.load(filename, vocabs=vocabs, batchsz=1)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(to_tensors(ts, lengths_key))\n",
        "    if shuffle:\n",
        "      dataset = dataset.shuffle(buffer_size=SHUF_BUF_SZ)\n",
        "    dataset = dataset.batch(batchsz, drop_remainder=True)\n",
        "    dataset = dataset.prefetch(NUM_PREFETCH)\n",
        "    dataset = strategy.experimental_distribute_dataset(dataset)\n",
        "    return dataset\n",
        "\n",
        "train_ds = create_dataset(strategy, reader, TRAIN, vocabs, BATCH_SIZE, LENGTHS_KEY, True)\n",
        "valid_ds = create_dataset(strategy, reader, VALID, vocabs, BATCH_SIZE, LENGTHS_KEY)\n",
        "test_ds = create_dataset(strategy, reader, TEST, vocabs, BATCH_SIZE, LENGTHS_KEY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUfsgecat_Ni",
        "colab_type": "text"
      },
      "source": [
        "We are finally ready to train our model.  We are going to use `tf.eager` to train, and to do this we can use the `EagerOptimizer`.  `8 mile` has the same class defined in PyTorch and TensorFlow, and for most cases, the API can be used identically.  Here we are going to tell `EagerOptimizer` to use `adam` with a learning rate of `1e-3`.  We need a loss function (defined by `loss` below) for the optimizer as well.\n",
        "\n",
        "The next thing we do is define a function to train a whole epoch of data on the TPU using `tf.distribute`.\n",
        "\n",
        "TPUs require that any eager code is compiled with `tf.function`.  The `_replicated_train_step` internal function is basically what each TPU core will run.  The results from each core need to be aggregated, and this is done with `_distributed_train_step`, which is compiled with via the `@tf.function` annotation, including its underlying replica train function.  The results from each replica include a per-replica loss, a per-replica number of datapoints that were processed (which is the batch size).  We use the `strategy.reduce` call to aggregate these, and we use `tf.Variable`s for each to aggregate each step in the epoch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv0dg7LQR4b4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from eight_mile.tf.optz import EagerOptimizer\n",
        "from eight_mile.tf.layers import get_shape_as_list\n",
        "from baseline.tf.tfy import SET_TRAIN_FLAG\n",
        "\n",
        "def loss(model, x, y):\n",
        "    y_ = model(x)\n",
        "    return tf.compat.v1.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n",
        "\n",
        "optimizer = EagerOptimizer(loss, optim='adam', lr=0.001)\n",
        "\n",
        "def train_epoch(optimizer, model, train_ds, strategy):\n",
        "    def _replicated_train_step(inputs):\n",
        "        \"\"\"Replicated training step.\"\"\"\n",
        "        features, y = inputs\n",
        "        per_replica_loss = optimizer.update(model, features, y, strategy.num_replicas_in_sync)\n",
        "        per_replica_batchsz = tf.cast(get_shape_as_list(y)[0], tf.float32)\n",
        "        per_replica_report_loss = per_replica_loss * per_replica_batchsz\n",
        "        return per_replica_report_loss, per_replica_batchsz\n",
        "\n",
        "    @tf.function\n",
        "    def _distributed_train_step(inputs):\n",
        "        per_replica_loss, per_replica_batchsz = strategy.experimental_run_v2(_replicated_train_step, args=(inputs,))\n",
        "        return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None), strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_batchsz, axis=None)\n",
        "\n",
        "    epoch_loss = tf.Variable(0.0)\n",
        "    epoch_div = tf.Variable(0.0)\n",
        "    with strategy.scope():\n",
        "        SET_TRAIN_FLAG(True)\n",
        "        train_iter = iter(train_ds)\n",
        "        for next_x in train_iter:\n",
        "            step_loss, step_batchsz = _distributed_train_step(next_x)\n",
        "            epoch_loss.assign_add(step_loss)\n",
        "            epoch_div.assign_add(step_batchsz)\n",
        "        epoch_loss = epoch_loss.numpy()\n",
        "        epoch_div = epoch_div.numpy()\n",
        "        return epoch_loss / epoch_div\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oWJhHPav0Yt",
        "colab_type": "text"
      },
      "source": [
        "We finally have all the pieces we need to train on TPUs!  Now lets train an epoch and see our average loss and elapsed wall clock time in seconds!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnqVkDemVuQX",
        "colab_type": "code",
        "outputId": "2d611b23-e462-4f21-b2fe-e10a7cd15a8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "avg_loss = train_epoch(optimizer, model, train_ds, strategy=strategy)\n",
        "elapsed = time.time() - start_time\n",
        "print(avg_loss, elapsed)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.028293055 16.16217279434204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvaIutp2wBrP",
        "colab_type": "text"
      },
      "source": [
        "We would like to know how we are doing, so we need to define a routine to validate our model on some data. Like in training, we are going to replicate the validation across multiple TPUs, and aggregate the results.  In this case we would also like to know the accuracy of our classifier, so we will count up in each replica how many datapoints were correct and divide by the total number of datapoints.\n",
        "\n",
        "Otherwise the code is quite similar to our `train_epoch` function.\n",
        "\n",
        "You might be wondering about the `SET_TRAIN_FLAG()` function that we set in both the `train_epoch` and `test_epoch`.  This sets a global variable inside MEAD that determines if things like dropout should be applied.  It is equivalent to `model.train()` and `model.eval()` in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AujlOKBFfvJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_epoch(model, test_ds, strategy):\n",
        "\n",
        "    def _replica_test_step(inputs):\n",
        "        features, y = inputs\n",
        "        y = tf.cast(y, tf.int64)\n",
        "        logits = model(features)\n",
        "        y_ = tf.argmax(logits, axis=1, output_type=tf.int64)\n",
        "        per_replica_loss = tf.compat.v1.losses.sparse_softmax_cross_entropy(labels=y, logits=logits)\n",
        "        per_replica_batchsz = tf.cast(get_shape_as_list(y)[0], tf.float32)\n",
        "        per_replica_report_loss = per_replica_loss * per_replica_batchsz\n",
        "        return per_replica_report_loss, per_replica_batchsz, tf.cast(tf.reduce_sum(tf.cast(y == y_, tf.int64)), tf.float32)\n",
        "\n",
        "    @tf.function\n",
        "    def _distributed_test_step(inputs):\n",
        "        per_replica_loss, per_replica_batchsz, per_replica_correct = strategy.experimental_run_v2(_replica_test_step, args=(inputs,))\n",
        "        step_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None)\n",
        "        step_batchsz = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_batchsz, axis=None)\n",
        "        step_corr = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_correct, axis=None)\n",
        "        return step_loss, step_batchsz, step_corr\n",
        "    \n",
        "    with strategy.scope():\n",
        "        total_loss = tf.Variable(0.0)\n",
        "        total_norm = tf.Variable(0.0)\n",
        "        total_corr = tf.Variable(0.0)\n",
        "        SET_TRAIN_FLAG(False)\n",
        "        test_iter = iter(test_ds)\n",
        "\n",
        "        for next_x in test_iter: \n",
        "            step_loss, step_batchsz, step_corr = _distributed_test_step(next_x)\n",
        "            total_loss.assign_add(step_loss)\n",
        "            total_norm.assign_add(step_batchsz)\n",
        "            total_corr.assign_add(step_corr)\n",
        "\n",
        "        total_loss = total_loss.numpy()\n",
        "        total_corr = total_corr.numpy()\n",
        "        total_norm = total_norm.numpy()\n",
        "        acc = total_corr / float(total_norm)\n",
        "        avg_loss = total_loss / float(total_norm)\n",
        "        return acc, avg_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDn-OlkFwwJz",
        "colab_type": "text"
      },
      "source": [
        "Okay, lets run an test iteration:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z53ZfK0mj0gU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c413de7a-3311-4338-9b03-99eb3085a9d4"
      },
      "source": [
        "start_time = time.time()\n",
        "acc, avg_loss = test_epoch(model, valid_ds, strategy=strategy)\n",
        "elapsed = time.time() - start_time\n",
        "print(acc, avg_loss, elapsed)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.84375 0.3882710138956706 2.0577547550201416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWchc2Qjw36h",
        "colab_type": "text"
      },
      "source": [
        "Lets run one more epoch and then we will evaluate our model on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pENEfKtVo3iA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c7de0f5f-7f36-4d58-fb2b-c4735ba9e62d"
      },
      "source": [
        "start_time = time.time()\n",
        "avg_loss = train_epoch(optimizer, model, train_ds, strategy=strategy)\n",
        "elapsed = time.time() - start_time\n",
        "print('Train', avg_loss, elapsed)\n",
        "start_time = time.time()\n",
        "acc, avg_loss = test_epoch(model, valid_ds, strategy=strategy)\n",
        "elapsed = time.time() - start_time\n",
        "print('Valid', acc, avg_loss, elapsed)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train 0.022798203 12.71997618675232\n",
            "Valid 0.84765625 0.3976578712463379 0.9341402053833008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4Jgm7aBxHni",
        "colab_type": "text"
      },
      "source": [
        "Ok, we have trained the model for 2 epochs (complete passes over the dataset), with the word divided over 8 TPUs. Finally, we will run the same model, but on the test data this time, and the final accuracy is the one that we would want to report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSHgu7U9pJMw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38b9edd8-aeab-49dd-a67f-d1d79b114da2"
      },
      "source": [
        "start_time = time.time()\n",
        "acc, avg_loss = test_epoch(model, test_ds, strategy=strategy)\n",
        "elapsed = time.time() - start_time\n",
        "print('Test', acc, avg_loss, elapsed)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test 0.8638392857142857 0.35195088386535645 1.262049674987793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFL8yEC2xXkt",
        "colab_type": "text"
      },
      "source": [
        "**Conclusion**\n",
        "\n",
        "In this example, we dug into the internals of MEAD to make our own training loop and evaluation to make the Baseline CNN classifier run on Google TPUs!"
      ]
    }
  ]
}